{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "43b4e7e6",
   "metadata": {},
   "source": [
    "This is the code for server. The server would calculate the individual trust score as well as the aggregated global model's trust score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c693eb9a",
   "metadata": {},
   "source": [
    "# Importing libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a5bb1d8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "from copy import deepcopy\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, utils\n",
    "import torch\n",
    "\n",
    "import torchsummary\n",
    "from torchsummary import summary\n",
    "\n",
    "\n",
    "from create_MNIST_datasets import get_MNIST, plot_samples\n",
    "from alibi.confidence import TrustScore\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "56a4ddfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import syft as sy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18c5adb2",
   "metadata": {},
   "source": [
    "# Test set preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d1a58d98",
   "metadata": {},
   "outputs": [],
   "source": [
    "testing_set = torch.load('server_t.pth')\n",
    "train_data = torch.load('server.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3f88b859",
   "metadata": {},
   "outputs": [],
   "source": [
    "class autoencoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Conv2d(1, 16, 3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2),  \n",
    "            nn.Conv2d(16, 8, 3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2), \n",
    "            \n",
    "            nn.Conv2d(8, 4, 3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2), \n",
    "            \n",
    "        )\n",
    "        self.decoder = nn.Sequential(\n",
    "            \n",
    "            nn.ConvTranspose2d(4, 8, 3, stride=2),\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(8, 16, 2, stride=2),\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(16, 32, 2, stride=2),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(32, 1, 3, padding=1) \n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.encoder(x)\n",
    "        x = self.decoder(x)\n",
    "        x = torch.sigmoid(x)  \n",
    "        return x\n",
    "model = autoencoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0d2a03eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.load('auto_encoder.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bcaa378",
   "metadata": {},
   "source": [
    "The server loaded the saved autoencoder model, which they would use to reduce the dimension of the data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a5cda5b",
   "metadata": {},
   "source": [
    "The server would connect to each client seperately and for each client, in the drop down box the connectivity status would show connected. Also, if the clients are connected - there would be a live status shown by animated star in the clients side. The server would first establish connection and send the initial model parameters to the clients."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e6a6493",
   "metadata": {},
   "source": [
    "# Connection establishment with client0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4314ac04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎤  🎸  ♪♪♪ Joining Duet ♫♫♫  🎻  🎹\n",
      "\n",
      "♫♫♫ >\u001b[93m DISCLAIMER\u001b[0m: \u001b[1mDuet is an experimental feature currently in beta.\n",
      "♫♫♫ > Use at your own risk.\n",
      "\u001b[0m\n",
      "\u001b[1m\n",
      "    > ❤️ \u001b[91mLove\u001b[0m \u001b[92mDuet\u001b[0m? \u001b[93mPlease\u001b[0m \u001b[94mconsider\u001b[0m \u001b[95msupporting\u001b[0m \u001b[91mour\u001b[0m \u001b[93mcommunity!\u001b[0m\n",
      "    > https://github.com/sponsors/OpenMined\u001b[1m\n",
      "\n",
      "♫♫♫ > Punching through firewall to OpenGrid Network Node at:\n",
      "♫♫♫ > http://ec2-18-218-7-180.us-east-2.compute.amazonaws.com:5000\n",
      "♫♫♫ >\n",
      "♫♫♫ > ...waiting for response from OpenGrid Network... \n",
      "♫♫♫ > \u001b[92mDONE!\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/syeda/courses/fl/lib/python3.8/site-packages/aiortc/rtcdtlstransport.py:211: CryptographyDeprecationWarning: This version of cryptography contains a temporary pyOpenSSL fallback path. Upgrade pyOpenSSL now.\n",
      "  _openssl_assert(lib.SSL_CTX_use_certificate(ctx, self._cert._x509) == 1)  # type: ignore\n",
      "/Users/syeda/courses/fl/lib/python3.8/site-packages/aiortc/rtcdtlstransport.py:186: CryptographyDeprecationWarning: This version of cryptography contains a temporary pyOpenSSL fallback path. Upgrade pyOpenSSL now.\n",
      "  value=certificate_digest(self._cert._x509),  # type: ignore\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "♫♫♫ > \u001b[92mCONNECTED!\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "duet_0 = sy.join_duet(loopback=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bdd02ab",
   "metadata": {},
   "source": [
    "# Connection establishment with client1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "864c133f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎤  🎸  ♪♪♪ Joining Duet ♫♫♫  🎻  🎹\n",
      "\n",
      "♫♫♫ >\u001b[93m DISCLAIMER\u001b[0m: \u001b[1mDuet is an experimental feature currently in beta.\n",
      "♫♫♫ > Use at your own risk.\n",
      "\u001b[0m\n",
      "\u001b[1m\n",
      "    > ❤️ \u001b[91mLove\u001b[0m \u001b[92mDuet\u001b[0m? \u001b[93mPlease\u001b[0m \u001b[94mconsider\u001b[0m \u001b[95msupporting\u001b[0m \u001b[91mour\u001b[0m \u001b[93mcommunity!\u001b[0m\n",
      "    > https://github.com/sponsors/OpenMined\u001b[1m\n",
      "\n",
      "♫♫♫ > Punching through firewall to OpenGrid Network Node at:\n",
      "♫♫♫ > http://ec2-18-218-7-180.us-east-2.compute.amazonaws.com:5000\n",
      "♫♫♫ >\n",
      "♫♫♫ > ...waiting for response from OpenGrid Network... \n",
      "♫♫♫ > \u001b[92mDONE!\u001b[0m\n",
      "\n",
      "♫♫♫ > \u001b[92mCONNECTED!\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "duet_1 = sy.join_duet(loopback=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c68e044",
   "metadata": {},
   "source": [
    "# Connection establishment with client2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "aa35af81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎤  🎸  ♪♪♪ Joining Duet ♫♫♫  🎻  🎹\n",
      "\n",
      "♫♫♫ >\u001b[93m DISCLAIMER\u001b[0m: \u001b[1mDuet is an experimental feature currently in beta.\n",
      "♫♫♫ > Use at your own risk.\n",
      "\u001b[0m\n",
      "\u001b[1m\n",
      "    > ❤️ \u001b[91mLove\u001b[0m \u001b[92mDuet\u001b[0m? \u001b[93mPlease\u001b[0m \u001b[94mconsider\u001b[0m \u001b[95msupporting\u001b[0m \u001b[91mour\u001b[0m \u001b[93mcommunity!\u001b[0m\n",
      "    > https://github.com/sponsors/OpenMined\u001b[1m\n",
      "\n",
      "♫♫♫ > Punching through firewall to OpenGrid Network Node at:\n",
      "♫♫♫ > http://ec2-18-218-7-180.us-east-2.compute.amazonaws.com:5000\n",
      "♫♫♫ >\n",
      "♫♫♫ > ...waiting for response from OpenGrid Network... \n",
      "♫♫♫ > \u001b[92mDONE!\u001b[0m\n",
      "\n",
      "♫♫♫ > \u001b[92mCONNECTED!\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "duet_2 = sy.join_duet(loopback=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b9b179e",
   "metadata": {},
   "source": [
    "# Model creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e7c3fabc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "        self.fc = nn.Linear(784, 10)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.fc(x)\n",
    "        x = F.softmax(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "07ce1293",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_server = torch.load('initial_model.pth')\n",
    "model_server_0 = deepcopy(model_server)\n",
    "model_server_1 = deepcopy(model_server)\n",
    "model_server_2 = deepcopy(model_server)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac011d3b",
   "metadata": {},
   "source": [
    "# Initial model parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a0376735",
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = torch.nn.utils.parameters_to_vector(model_server.parameters())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28a8d250",
   "metadata": {},
   "source": [
    "\n",
    "# The initial model parameters sent to clients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "01cbebae",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/syeda/courses/fl/lib/python3.8/site-packages/torch/_tensor.py:1083: UserWarning: The .grad attribute of a Tensor that is not a leaf Tensor is being accessed. Its .grad attribute won't be populated during autograd.backward(). If you indeed want the .grad field to be populated for a non-leaf Tensor, use .retain_grad() on the non-leaf Tensor. If you access the non-leaf Tensor by mistake, make sure you access the leaf Tensor instead. See github.com/pytorch/pytorch/pull/30531 for more informations. (Triggered internally at  /Users/runner/work/pytorch/pytorch/pytorch/build/aten/src/ATen/core/TensorBody.h:482.)\n",
      "  return self._grad\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<syft.proxy.torch.TensorPointer at 0x14dca3cd0>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parameters.send(duet_0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8ffc5454",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<syft.proxy.torch.TensorPointer at 0x14edc3e50>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parameters.send(duet_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "94652f7a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<syft.proxy.torch.TensorPointer at 0x14e276040>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parameters.send(duet_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e565a37",
   "metadata": {},
   "source": [
    "The above part send the initial model parameters to the clients and would wait until they get the model update from the client. After running upto this part we would move to the client code to receive the model from here and run upto end and return back here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "431e6415",
   "metadata": {},
   "source": [
    "# Model update from client0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d23a82d1",
   "metadata": {},
   "source": [
    "The parts below is after the model update is achieved from the clients and we would run the code upto end to calculate the trust score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "77c58c3f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Tags</th>\n",
       "      <th>Description</th>\n",
       "      <th>object_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>&lt;UID: 99b57a43fd3049aaab0fe35cd74af523&gt;</td>\n",
       "      <td>[]</td>\n",
       "      <td></td>\n",
       "      <td>&lt;class 'torch.Tensor'&gt;</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        ID Tags Description  \\\n",
       "0  <UID: 99b57a43fd3049aaab0fe35cd74af523>   []               \n",
       "\n",
       "              object_type  \n",
       "0  <class 'torch.Tensor'>  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "duet_0.store.pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "36db58f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2022-12-03T13:17:20.059371-0500][CRITICAL][logger]][47219] You do not have permission to .get() Object with ID: <UID: 99b57a43fd3049aaab0fe35cd74af523>Please submit a request.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You do not have permission to .get() Object with ID: <UID: 99b57a43fd3049aaab0fe35cd74af523>Please submit a request.\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    duet_0.store[0].get()\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "904f09ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "duet_0.store[0].request(reason=\"Please approve,updated parameters are needeed for aggregating\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a2e4d3ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "y0 = duet_0.store[0].get()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "794d9d5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.nn.utils.vector_to_parameters(y0,model_server_0.parameters())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c8ef5c2",
   "metadata": {},
   "source": [
    "# Model update from client1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5993aa9e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Tags</th>\n",
       "      <th>Description</th>\n",
       "      <th>object_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>&lt;UID: 8284af6a527f411fb27cb556de681280&gt;</td>\n",
       "      <td>[]</td>\n",
       "      <td></td>\n",
       "      <td>&lt;class 'torch.Tensor'&gt;</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        ID Tags Description  \\\n",
       "0  <UID: 8284af6a527f411fb27cb556de681280>   []               \n",
       "\n",
       "              object_type  \n",
       "0  <class 'torch.Tensor'>  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "duet_1.store.pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4f366ee3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2022-12-03T13:17:21.642983-0500][CRITICAL][logger]][47219] You do not have permission to .get() Object with ID: <UID: 8284af6a527f411fb27cb556de681280>Please submit a request.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You do not have permission to .get() Object with ID: <UID: 8284af6a527f411fb27cb556de681280>Please submit a request.\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    duet_1.store[0].get()\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "94b44356",
   "metadata": {},
   "outputs": [],
   "source": [
    "duet_1.store[0].request(reason=\"Please approve,updated parameters are needeed for aggregating\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3a8092e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "y1 = duet_1.store[0].get()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df48ec75",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f4e285d6",
   "metadata": {},
   "source": [
    "# Model update for client 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "35a31270",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Tags</th>\n",
       "      <th>Description</th>\n",
       "      <th>object_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>&lt;UID: 433e32e28da340af84c4f9e5bc536a3e&gt;</td>\n",
       "      <td>[]</td>\n",
       "      <td></td>\n",
       "      <td>&lt;class 'torch.Tensor'&gt;</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        ID Tags Description  \\\n",
       "0  <UID: 433e32e28da340af84c4f9e5bc536a3e>   []               \n",
       "\n",
       "              object_type  \n",
       "0  <class 'torch.Tensor'>  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "duet_2.store.pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "146e98b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2022-12-03T13:17:22.957912-0500][CRITICAL][logger]][47219] You do not have permission to .get() Object with ID: <UID: 433e32e28da340af84c4f9e5bc536a3e>Please submit a request.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You do not have permission to .get() Object with ID: <UID: 433e32e28da340af84c4f9e5bc536a3e>Please submit a request.\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    duet_2.store[0].get()\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "94c63004",
   "metadata": {},
   "outputs": [],
   "source": [
    "duet_2.store[0].request(reason=\"Please approve,updated parameters are needeed for aggregating\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4d5207b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "y2 = duet_2.store[0].get()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b74fb6eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def trust_score(test_samples, model_update, model):\n",
    "    ts = TrustScore()\n",
    "    encoded_tests=[]\n",
    "    model_pred_test=[]\n",
    "    x_tests=[]\n",
    "    y_tests=[]\n",
    "    for idx, (features,labels) in enumerate(test_samples):\n",
    "        x_tests.append(features)\n",
    "        predictions = model.encoder(features)\n",
    "        encoded_tests.append(predictions)\n",
    "        pred_test = model_update(features)\n",
    "        model_pred_test.append(pred_test)\n",
    "        y_tests.append(labels)\n",
    "        ts.fit(encoded_tests[0].detach().numpy(), y_tests[0], classes=10) \n",
    "        score, closest_class = ts.score(encoded_tests[0].detach().numpy(),model_pred_test[0].detach().numpy(), k=5)\n",
    "        print(score)\n",
    "        print(np.average(score))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe063a82",
   "metadata": {},
   "source": [
    "# Trust score calculation local model 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "88652158",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.nn.utils.vector_to_parameters(y0,model_server_0.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "20eac0a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/s3/nn8rqkp92c3413g9w6xsc9y00000gn/T/ipykernel_47219/152961979.py:9: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  x = F.softmax(x)\n",
      "Reshaping data from (100, 4, 3, 3) to (100, 36) so k-d trees can be built.\n",
      "Reshaping data from (100, 4, 3, 3) to (100, 36) so k-d trees can be queried.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.91611646 0.34358722 0.49972999 0.90256775 0.85823481 0.90961676\n",
      " 0.50339453 0.37680687 1.00311859 0.72421246 0.6138791  0.51216341\n",
      " 0.59302116 0.55437738 0.86090176 1.13677235 0.51656371 1.0131434\n",
      " 0.94917909 0.7445584  0.71486194 0.79715564 0.63199327 0.62107411\n",
      " 0.62870972 0.84896971 0.31840206 0.87186778 0.79566815 0.51689551\n",
      " 0.52922323 1.20822625 0.54374973 0.70027123 0.78147525 0.74015425\n",
      " 0.79890176 1.28774936 1.19678849 0.79193382 0.68756491 0.85027316\n",
      " 1.16309566 0.67288066 0.94561179 0.84477671 0.81789819 0.35920462\n",
      " 0.54494544 0.87405807 0.85475375 0.74229579 0.35880865 0.42799714\n",
      " 1.27023576 1.07509349 1.00616037 0.82342658 0.97064903 1.01280357\n",
      " 0.77225156 0.82672859 0.50626132 0.6298686  0.71414943 0.83816074\n",
      " 0.75553036 0.99467816 0.44784061 0.75281613 0.96723007 1.06639903\n",
      " 0.46653034 0.68336037 0.84716958 1.18716772 0.91328876 0.84932318\n",
      " 0.52837709 0.51696602 0.69569312 0.64205454 0.48111738 0.78666242\n",
      " 0.98189232 0.84028484 0.5509518  0.70315346 0.58820458 0.63673888\n",
      " 0.57301467 0.6696631  0.84415393 0.68058911 0.89259268 0.68562178\n",
      " 0.82211305 1.04140556 0.78923101 0.97863253]\n",
      "0.7630641826598941\n"
     ]
    }
   ],
   "source": [
    "trust_score_local_model_0 = trust_score(testing_set, model_server_0, model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b351dc6",
   "metadata": {},
   "source": [
    "# Trust score calculation for local model 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "25d8bc76",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.nn.utils.vector_to_parameters(y1,model_server_1.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "9d03ca32",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/s3/nn8rqkp92c3413g9w6xsc9y00000gn/T/ipykernel_47219/152961979.py:9: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  x = F.softmax(x)\n",
      "Reshaping data from (100, 4, 3, 3) to (100, 36) so k-d trees can be built.\n",
      "Reshaping data from (100, 4, 3, 3) to (100, 36) so k-d trees can be queried.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.27317971 0.54494544 1.16309566 0.68562178 0.85027316 1.27023576\n",
      " 0.79715564 0.51656371 0.71414943 0.85823481 1.13677235 0.50626132\n",
      " 0.44784061 0.36904181 0.77957727 1.07444388 0.46653034 0.7445584\n",
      " 0.86090176 1.00311859 0.79193382 0.51689551 0.75281613 1.20822625\n",
      " 0.98189232 0.82672859 0.82211305 0.52837709 1.01280357 0.84896971\n",
      " 0.46335351 0.84033501 0.81789819 0.64205454 1.1699276  0.75553036\n",
      " 0.55437738 0.5509518  0.53620387 0.73599642 0.6138791  0.42799714\n",
      " 0.52922323 0.90961676 0.71486194 0.78926586 1.19678849 0.46685644\n",
      " 0.97064903 0.97863253 0.84932318 0.94917909 0.90256775 0.81182868\n",
      " 0.91328876 0.67288066 0.84415393 0.59302116 0.63199327 0.51216341\n",
      " 0.81803727 0.79036833 0.58524508 0.54374973 0.78666242 0.84028484\n",
      " 0.96723007 0.68756491 0.93638213 0.57301467 0.83816074 0.87186778\n",
      " 1.10601009 0.78147525 0.58820458 0.88669871 1.04140556 0.84716958\n",
      " 0.60149001 0.74015425 0.34358722 0.91611646 0.50339453 1.28774936\n",
      " 0.80506287 0.62107411 0.77225156 1.03626809 0.94561179 0.99467816\n",
      " 0.74229579 0.63673888 0.68336037 0.6298686  0.89259268 1.18716772\n",
      " 0.78923101 1.07509349 0.70027123 0.68058911]\n",
      "0.7877223563648654\n"
     ]
    }
   ],
   "source": [
    "trust_score_local_model_1 = trust_score(testing_set, model_server_1, model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd930438",
   "metadata": {},
   "source": [
    "#  Trust score calculation for local model 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "0027252d",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.nn.utils.vector_to_parameters(y2,model_server_2.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "b97c7d52",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/s3/nn8rqkp92c3413g9w6xsc9y00000gn/T/ipykernel_47219/152961979.py:9: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  x = F.softmax(x)\n",
      "Reshaping data from (100, 4, 3, 3) to (100, 36) so k-d trees can be built.\n",
      "Reshaping data from (100, 4, 3, 3) to (100, 36) so k-d trees can be queried.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.1699276  1.00311859 0.84280898 1.43548408 0.77957727 0.85823481\n",
      " 0.52837709 0.54494544 0.49972999 0.70027123 0.83816074 0.99467816\n",
      " 0.71486194 0.51696602 0.84896971 0.93638213 0.97863253 0.86090176\n",
      " 1.19678849 0.72421924 0.77225156 0.35920462 0.82672859 0.63199327\n",
      " 1.10601009 2.14198609 0.59302116 0.94917909 0.89259268 0.78926586\n",
      " 2.67465081 0.79193382 1.03626809 0.75553036 0.64205454 0.48111738\n",
      " 0.6696631  0.51656371 0.44135571 2.39779062 0.62107411 0.6138791\n",
      " 0.68562178 0.7364054  0.90256775 0.54374973 1.07509349 1.28774936\n",
      " 0.90961676 0.84415393 0.87186778 0.82342658 0.58820458 0.84028484\n",
      " 0.46335351 0.79890176 1.27023576 0.46653034 0.57301467 0.91328876\n",
      " 0.82211305 0.84716958 1.04140556 0.84932318 0.68756491 0.58524508\n",
      " 0.67288066 0.51216341 0.78666242 0.96723007 0.68058911 0.60167317\n",
      " 0.78923101 0.81789819 0.6298686  1.02676252 0.91611646 0.63673888\n",
      " 0.71414943 1.13677235 0.79715564 1.01280357 0.98189232 0.79668535\n",
      " 1.16309566 0.51689551 0.44784061 1.20822625 0.47129653 0.69569312\n",
      " 1.07444388 0.42799714 0.55437738 0.5509518  0.70658752 0.7445584\n",
      " 1.27317971 0.50339453 1.18716772 0.94561179]\n",
      "0.8405262902715295\n"
     ]
    }
   ],
   "source": [
    "trust_score_local_model_2 = trust_score(testing_set, model_server_2, model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5ca4c90",
   "metadata": {},
   "source": [
    "# Trust score calculation for global model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "ddb62835",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = (y1+y2+y0)/3\n",
    "torch.nn.utils.vector_to_parameters(y,model_server.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "e53393f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/s3/nn8rqkp92c3413g9w6xsc9y00000gn/T/ipykernel_47219/152961979.py:9: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  x = F.softmax(x)\n",
      "Reshaping data from (100, 4, 3, 3) to (100, 36) so k-d trees can be built.\n",
      "Reshaping data from (100, 4, 3, 3) to (100, 36) so k-d trees can be queried.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.74015425 0.54374973 0.7445584  0.57301467 0.6298686  0.51216341\n",
      " 0.84716958 0.64205454 0.46335351 1.07444388 0.79715564 0.62107411\n",
      " 0.94917909 2.67465081 0.70027123 0.91611646 1.13677235 0.48111738\n",
      " 0.68562178 0.86090176 1.16309566 0.51696602 1.07509349 0.97863253\n",
      " 0.51656371 0.81789819 0.79668535 0.82342658 1.27317971 0.78923101\n",
      " 0.79193382 1.18716772 0.58524508 1.01280357 0.52837709 1.19678849\n",
      " 0.37680687 0.54494544 0.34358722 0.78666242 0.94561179 1.1699276\n",
      " 0.79890176 0.91328876 0.63673888 0.75553036 0.84932318 0.6138791\n",
      " 0.84896971 0.90256775 0.50626132 0.89259268 0.84280898 0.82672859\n",
      " 0.82211305 0.63199327 0.83816074 0.69569312 1.10601009 1.20822625\n",
      " 0.87186778 0.84028484 0.96723007 0.71486194 0.49972999 1.27023576\n",
      " 0.98189232 0.46653034 0.6696631  0.50339453 0.44784061 0.51689551\n",
      " 0.84415393 0.77225156 0.85823481 0.42799714 0.52922323 0.59302116\n",
      " 0.68336037 0.68058911 0.68756491 0.84033501 0.99467816 0.78926586\n",
      " 0.71414943 0.90961676 0.5509518  0.55437738 0.93638213 0.77957727\n",
      " 0.35920462 1.04140556 0.97064903 0.60167317 0.72421924 1.00311859\n",
      " 0.79566815 0.58820458 0.67288066 1.28774936]\n",
      "0.7944473793828755\n"
     ]
    }
   ],
   "source": [
    "trust_score_global_model = trust_score(testing_set, model_server, model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "effdf548",
   "metadata": {},
   "source": [
    "None of the clients are malicious"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db04bd55",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
