{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c693eb9a",
   "metadata": {},
   "source": [
    "# Importing libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5bb1d8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, utils\n",
    "import torch\n",
    "import torchsummary\n",
    "from torchsummary import summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1a58d98",
   "metadata": {},
   "outputs": [],
   "source": [
    "testing_set = torch.load('server_t.pth')\n",
    "train_data = torch.load('server.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f88b859",
   "metadata": {},
   "outputs": [],
   "source": [
    "class autoencoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Conv2d(1, 16, 3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2),  \n",
    "            nn.Conv2d(16, 8, 3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2), \n",
    "            \n",
    "            nn.Conv2d(8, 4, 3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2), \n",
    "            \n",
    "        )\n",
    "        self.decoder = nn.Sequential(\n",
    "            \n",
    "            nn.ConvTranspose2d(4, 8, 3, stride=2),\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(8, 16, 2, stride=2),\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(16, 32, 2, stride=2),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(32, 1, 3, padding=1) \n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.encoder(x)\n",
    "        x = self.decoder(x)\n",
    "        x = torch.sigmoid(x)  \n",
    "        return x\n",
    "model = autoencoder()\n",
    "print(summary(model,(1,28,28)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7678b1b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_function = torch.nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters())\n",
    "epochs = 200\n",
    "outputs = []\n",
    "losses = []\n",
    "for e in range(epochs): \n",
    "    print(e)\n",
    "    total_loss = 0\n",
    "    for idx, (features,labels) in enumerate(train_data):\n",
    "        predictions= model(features)\n",
    "        loss = loss_function(predictions, features)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        losses.append(loss)\n",
    "    outputs.append((epochs, features, predictions)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a65ae7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(features[0].size(), predictions[0].size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19387121",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(predictions[71].detach().numpy().reshape(28,28))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4664354",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(features[71].detach().numpy().reshape(28,28))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6935984",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model, 'auto_encoder.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15dec06d",
   "metadata": {},
   "source": [
    "This is the code of an autoencoder model and we save this model,so that for each client and each case we can use the same model parameters. This model is used by the server to reduce the dimension of the MNIST feature which is an image of 28*28 pixels.  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
